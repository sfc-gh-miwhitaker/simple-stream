{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RFID Badge Event Simulator\n",
        "\n",
        "**What you're about to see:** Snowflake ingesting real-time data via REST API‚Äîno Kafka, no message queues, just HTTP POST.\n",
        "\n",
        "This notebook will:\n",
        "1. Validate your environment is ready\n",
        "2. Authenticate using JWT key-pair auth\n",
        "3. Open a streaming channel via REST API\n",
        "4. Send 1,000 badge events via HTTP POST\n",
        "5. Verify data landed in your tables\n",
        "\n",
        "**The Technology:** Snowpipe Streaming REST API (GA since Sept 2024)\n",
        "- Direct HTTP ingestion (no middleware)\n",
        "- 10 GB/sec throughput per table\n",
        "- Sub-10-second latency\n",
        "- Production-ready, fully managed by Snowflake\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Validation\n",
        "\n",
        "Let's verify your environment is properly configured before we start.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries and validate environment\n",
        "import snowflake.snowpark as snowpark\n",
        "from snowflake.snowpark.functions import col\n",
        "import _snowflake\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "session = snowpark.context.get_active_session()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT VALIDATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check 1: Database and schema exist\n",
        "try:\n",
        "    result = session.sql(\"SHOW DATABASES LIKE 'SNOWFLAKE_EXAMPLE'\").collect()\n",
        "    db_exists = len(result) > 0\n",
        "    print(f\"[{'PASS' if db_exists else 'FAIL'}] Database: SNOWFLAKE_EXAMPLE\")\n",
        "except Exception as e:\n",
        "    print(f\"[FAIL] Database check failed: {e}\")\n",
        "    db_exists = False\n",
        "\n",
        "# Check 2: Pipe exists\n",
        "try:\n",
        "    result = session.sql(\"\"\"\n",
        "        SELECT COUNT(*) as cnt \n",
        "        FROM SNOWFLAKE_EXAMPLE.INFORMATION_SCHEMA.PIPES \n",
        "        WHERE PIPE_SCHEMA = 'RAW_INGESTION' \n",
        "          AND PIPE_NAME = 'SFE_BADGE_EVENTS_PIPE'\n",
        "    \"\"\").collect()\n",
        "    pipe_exists = result[0]['CNT'] > 0\n",
        "    print(f\"[{'PASS' if pipe_exists else 'FAIL'}] Pipe: SFE_BADGE_EVENTS_PIPE\")\n",
        "except Exception as e:\n",
        "    print(f\"[FAIL] Pipe check failed: {e}\")\n",
        "    pipe_exists = False\n",
        "\n",
        "# Check 3: Target table exists\n",
        "try:\n",
        "    result = session.sql(\"\"\"\n",
        "        SELECT COUNT(*) as cnt \n",
        "        FROM SNOWFLAKE_EXAMPLE.INFORMATION_SCHEMA.TABLES \n",
        "        WHERE TABLE_SCHEMA = 'RAW_INGESTION' \n",
        "          AND TABLE_NAME = 'RAW_BADGE_EVENTS'\n",
        "    \"\"\").collect()\n",
        "    table_exists = result[0]['CNT'] > 0\n",
        "    print(f\"[{'PASS' if table_exists else 'FAIL'}] Table: RAW_BADGE_EVENTS\")\n",
        "except Exception as e:\n",
        "    print(f\"[FAIL] Table check failed: {e}\")\n",
        "    table_exists = False\n",
        "\n",
        "# Check 4: Secrets configured\n",
        "secrets_ok = True\n",
        "missing_secrets = []\n",
        "for secret_name in ['SFE_SS_JWT_KEY', 'SFE_SS_ACCOUNT', 'SFE_SS_USER']:\n",
        "    try:\n",
        "        # Try fully qualified name first\n",
        "        _snowflake.get_generic_secret_string(f'SNOWFLAKE_EXAMPLE.DEMO_REPO.{secret_name}')\n",
        "        print(f\"[PASS] Secret: {secret_name} configured\")\n",
        "    except Exception as e:\n",
        "        print(f\"[FAIL] Secret: {secret_name} NOT FOUND\")\n",
        "        print(f\"       Error: {str(e)}\")\n",
        "        missing_secrets.append(secret_name)\n",
        "        secrets_ok = False\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Summary\n",
        "all_ok = db_exists and pipe_exists and table_exists and secrets_ok\n",
        "\n",
        "if all_ok:\n",
        "    print(\"[READY] All prerequisites are configured.\")\n",
        "    print(\"        Continue to the next cell to start sending data.\")\n",
        "else:\n",
        "    print(\"[SETUP INCOMPLETE] Please fix the following:\")\n",
        "    if not db_exists or not pipe_exists or not table_exists:\n",
        "        print(\"   -> Run: sql/00_git_setup/03_deploy_from_git.sql\")\n",
        "    if not secrets_ok:\n",
        "        print(\"   -> Run: sql/00_git_setup/02_configure_secrets.sql\")\n",
        "        print(f\"   -> Missing: {', '.join(missing_secrets)}\")\n",
        "    print()\n",
        "    print(\"   After fixing, re-run this cell to validate.\")\n",
        "    raise SystemExit(\"Environment validation failed - please complete setup first\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 2: Load Authentication Configuration\n",
        "\n",
        "Now we'll load your credentials from Snowflake secrets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load credentials from Snowflake secrets\n",
        "import hashlib\n",
        "import base64\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from cryptography.hazmat.primitives import serialization, hashes\n",
        "from cryptography.hazmat.primitives.asymmetric import padding\n",
        "\n",
        "# Load secrets (fully qualified names required)\n",
        "private_key_pem = _snowflake.get_generic_secret_string('SNOWFLAKE_EXAMPLE.DEMO_REPO.SFE_SS_JWT_KEY')\n",
        "account = _snowflake.get_generic_secret_string('SNOWFLAKE_EXAMPLE.DEMO_REPO.SFE_SS_ACCOUNT')\n",
        "user = _snowflake.get_generic_secret_string('SNOWFLAKE_EXAMPLE.DEMO_REPO.SFE_SS_USER')\n",
        "\n",
        "config = {\n",
        "    'account': account,\n",
        "    'user': user,\n",
        "    'private_key_pem': private_key_pem,\n",
        "    'database': 'SNOWFLAKE_EXAMPLE',\n",
        "    'schema': 'RAW_INGESTION',\n",
        "    'pipe': 'SFE_BADGE_EVENTS_PIPE'\n",
        "}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"AUTHENTICATION CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Account: {config['account']}\")\n",
        "print(f\"User: {config['user']}\")\n",
        "print(f\"Target Pipe: {config['database']}.{config['schema']}.{config['pipe']}\")\n",
        "print(f\"Private Key: {len(config['private_key_pem'])} bytes loaded\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Initialize JWT Authentication\n",
        "\n",
        "We'll create a JWT token generator using RS256 key-pair authentication‚Äîthe same method Snowflake connectors use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JWT Authentication Class\n",
        "class SnowflakeAuth:\n",
        "    \"\"\"Generates JWT tokens for Snowflake REST API authentication\"\"\"\n",
        "    \n",
        "    def __init__(self, account, user, private_key_pem):\n",
        "        self.account = account\n",
        "        self.user = user\n",
        "        self.private_key = self._load_private_key(private_key_pem)\n",
        "        self.public_key_fingerprint = self._calculate_fingerprint()\n",
        "    \n",
        "    def _load_private_key(self, pem_string):\n",
        "        \"\"\"Load RSA private key from PEM format\"\"\"\n",
        "        key_bytes = pem_string.encode() if isinstance(pem_string, str) else pem_string\n",
        "        return serialization.load_pem_private_key(key_bytes, password=None)\n",
        "    \n",
        "    @staticmethod\n",
        "    def _base64url_encode(data: bytes) -> str:\n",
        "        \"\"\"Base64 URL-safe encoding (no padding)\"\"\"\n",
        "        return base64.urlsafe_b64encode(data).rstrip(b\"=\").decode(\"utf-8\")\n",
        "    \n",
        "    def _calculate_fingerprint(self):\n",
        "        \"\"\"Calculate SHA256 fingerprint of public key\"\"\"\n",
        "        public_key = self.private_key.public_key()\n",
        "        public_key_der = public_key.public_bytes(\n",
        "            encoding=serialization.Encoding.DER,\n",
        "            format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
        "        )\n",
        "        sha256_hash = hashlib.sha256(public_key_der).digest()\n",
        "        return 'SHA256:' + base64.b64encode(sha256_hash).decode('utf-8')\n",
        "    \n",
        "    def generate_jwt(self, expiration_minutes=59):\n",
        "        \"\"\"Generate JWT token (max 60 minutes lifetime)\"\"\"\n",
        "        now = datetime.utcnow()\n",
        "        qualified_username = f\"{self.account}.{self.user}\".upper()\n",
        "        \n",
        "        # JWT payload\n",
        "        payload = {\n",
        "            \"iss\": f\"{qualified_username}.{self.public_key_fingerprint}\",\n",
        "            \"sub\": qualified_username,\n",
        "            \"iat\": int(now.timestamp()),\n",
        "            \"exp\": int((now + timedelta(minutes=expiration_minutes)).timestamp())\n",
        "        }\n",
        "        \n",
        "        # Build JWT: header.payload.signature\n",
        "        header = {\"alg\": \"RS256\", \"typ\": \"JWT\"}\n",
        "        header_segment = self._base64url_encode(\n",
        "            json.dumps(header, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "        )\n",
        "        payload_segment = self._base64url_encode(\n",
        "            json.dumps(payload, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "        )\n",
        "        signing_input = f\"{header_segment}.{payload_segment}\".encode(\"utf-8\")\n",
        "        signature = self.private_key.sign(signing_input, padding.PKCS1v15(), hashes.SHA256())\n",
        "        signature_segment = self._base64url_encode(signature)\n",
        "        \n",
        "        return f\"{header_segment}.{payload_segment}.{signature_segment}\"\n",
        "\n",
        "# Initialize authenticator\n",
        "auth = SnowflakeAuth(\n",
        "    account=config['account'],\n",
        "    user=config['user'],\n",
        "    private_key_pem=config['private_key_pem']\n",
        ")\n",
        "\n",
        "# Verify we can generate tokens\n",
        "token = auth.generate_jwt()\n",
        "print(\"=\"*70)\n",
        "print(\"JWT AUTHENTICATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Key Fingerprint: {auth.public_key_fingerprint[:40]}...\")\n",
        "print(f\"JWT Token Generated: {len(token)} bytes\")\n",
        "print(f\"Preview: {token[:60]}...\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build the REST API Client\n",
        "\n",
        "This is where it gets interesting. We'll create a client that talks directly to Snowflake's streaming endpoints.\n",
        "\n",
        "**The 3-Step REST API Flow:**\n",
        "1. **GET** `/v2/streaming/hostname` ‚Üí Get control plane URL\n",
        "2. **POST** `/v2/streaming/.../pipes/{PIPE}:open-channel` ‚Üí Open streaming channel\n",
        "3. **POST** `/v2/streaming/.../channels/{CHANNEL}:insert-rows` ‚Üí Send data (THIS IS IT!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Snowpipe Streaming REST API Client\n",
        "class SnowpipeStreamingClient:\n",
        "    \"\"\"Direct HTTP client for Snowflake's streaming ingestion API\"\"\"\n",
        "    \n",
        "    def __init__(self, auth, database, schema, pipe):\n",
        "        self.auth = auth\n",
        "        self.database = database\n",
        "        self.schema = schema\n",
        "        self.pipe = pipe\n",
        "        \n",
        "        # Build account URL\n",
        "        account_for_url = auth.account.replace('_', '-').lower()\n",
        "        self.account_url = f\"https://{account_for_url}.snowflakecomputing.com\"\n",
        "        \n",
        "        # Session state (populated during workflow)\n",
        "        self.control_host = None\n",
        "        self.ingest_host = None\n",
        "        self.scoped_token = None\n",
        "        self.continuation_token = None\n",
        "    \n",
        "    def get_control_host(self):\n",
        "        \"\"\"Step 1: Discover the control plane hostname\"\"\"\n",
        "        jwt_token = self.auth.generate_jwt()\n",
        "        \n",
        "        response = requests.get(\n",
        "            f\"{self.account_url}/v2/streaming/hostname\",\n",
        "            headers={\"Authorization\": f\"Bearer {jwt_token}\"}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        self.control_host = response.text.strip('\"')\n",
        "        return self.control_host\n",
        "    \n",
        "    def open_channel(self, channel_name):\n",
        "        \"\"\"Step 2: Open a streaming channel (returns ingest host + scoped token)\"\"\"\n",
        "        if not self.control_host:\n",
        "            self.get_control_host()\n",
        "        \n",
        "        jwt_token = self.auth.generate_jwt()\n",
        "        url = f\"https://{self.control_host}/v2/streaming/databases/{self.database}/schemas/{self.schema}/pipes/{self.pipe}:open-channel\"\n",
        "        \n",
        "        response = requests.post(\n",
        "            url,\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json={\"channel_name\": channel_name}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        data = response.json()\n",
        "        self.ingest_host = data['ingest_host']\n",
        "        self.scoped_token = data['scoped_token']\n",
        "        self.continuation_token = data['continuation_token']\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def insert_rows(self, channel_name, rows):\n",
        "        \"\"\"Step 3: Send data via HTTP POST (THE MAIN EVENT!)\"\"\"\n",
        "        url = f\"https://{self.ingest_host}/v2/streaming/databases/{self.database}/schemas/{self.schema}/pipes/{self.pipe}/channels/{channel_name}:insert-rows\"\n",
        "        \n",
        "        response = requests.post(\n",
        "            url,\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {self.scoped_token}\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"X-Snowflake-Streaming-Continuation-Token\": self.continuation_token\n",
        "            },\n",
        "            json={\"rows\": rows}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        result = response.json()\n",
        "        self.continuation_token = result.get('continuation_token', self.continuation_token)\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Initialize client\n",
        "client = SnowpipeStreamingClient(\n",
        "    auth=auth,\n",
        "    database=config['database'],\n",
        "    schema=config['schema'],\n",
        "    pipe=config['pipe']\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"REST API CLIENT READY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Account URL: {client.account_url}\")\n",
        "print(f\"Target: {client.database}.{client.schema}.{client.pipe}\")\n",
        "print(\"Ready to stream data via HTTP POST\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Sample RFID Events\n",
        "\n",
        "Let's create realistic badge scan events. We'll simulate 100 employees accessing 20 zones via 10 RFID readers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RFID Badge Event Generator\n",
        "class BadgeEventGenerator:\n",
        "    \"\"\"Generates realistic RFID badge scan events\"\"\"\n",
        "    \n",
        "    def __init__(self, num_users=100, num_zones=20, num_readers=10):\n",
        "        self.badge_ids = [f\"BADGE-{str(i).zfill(5)}\" for i in range(1, num_users + 1)]\n",
        "        self.user_ids = [f\"USR-{str(i).zfill(3)}\" for i in range(1, num_users + 1)]\n",
        "        self.zone_ids = [f\"ZONE-{zone_type}-{i}\" \n",
        "                        for zone_type in [\"LOBBY\", \"OFFICE\", \"CONF\", \"SECURE\", \"PARKING\"]\n",
        "                        for i in range(1, (num_zones // 5) + 1)]\n",
        "        self.reader_ids = [f\"RDR-{str(i).zfill(3)}\" for i in range(1, num_readers + 1)]\n",
        "        self.directions = [\"ENTRY\", \"EXIT\"]\n",
        "    \n",
        "    def generate_event(self, timestamp=None):\n",
        "        \"\"\"Generate a single badge scan event\"\"\"\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.utcnow()\n",
        "        \n",
        "        user_idx = random.randint(0, len(self.user_ids) - 1)\n",
        "        \n",
        "        return {\n",
        "            \"badge_id\": self.badge_ids[user_idx],\n",
        "            \"user_id\": self.user_ids[user_idx],\n",
        "            \"zone_id\": random.choice(self.zone_ids),\n",
        "            \"event_timestamp\": timestamp.isoformat() + \"Z\",\n",
        "            \"event_type\": random.choice(self.directions),\n",
        "            \"reader_id\": random.choice(self.reader_ids),\n",
        "            \"signal_strength\": random.randint(-85, -20),\n",
        "            \"direction\": random.choice(self.directions)\n",
        "        }\n",
        "    \n",
        "    def generate_batch(self, count=100, start_time=None):\n",
        "        \"\"\"Generate a batch of events with realistic timestamps\"\"\"\n",
        "        if start_time is None:\n",
        "            start_time = datetime.utcnow()\n",
        "        \n",
        "        events = []\n",
        "        for i in range(count):\n",
        "            timestamp = start_time + timedelta(seconds=i*0.01)  # 10ms apart\n",
        "            events.append(self.generate_event(timestamp))\n",
        "        \n",
        "        return events\n",
        "\n",
        "# Initialize generator\n",
        "generator = BadgeEventGenerator(num_users=100, num_zones=20, num_readers=10)\n",
        "\n",
        "# Generate one sample to show what we're sending\n",
        "sample = generator.generate_event()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVENT GENERATOR READY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Simulating: 100 users, 20 zones, 10 readers\")\n",
        "print(f\"Sample event generated:\")\n",
        "print()\n",
        "print(json.dumps(sample, indent=2))\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: THE DEMO - Stream Data to Snowflake\n",
        "\n",
        "**This is it!** Watch as we send 1,000 RFID events directly to Snowflake via HTTP POST.\n",
        "\n",
        "No Kafka. No Kinesis. No message queues. Just REST API calls hitting Snowflake's ingestion endpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the streaming demo\n",
        "def stream_events_to_snowflake(num_events=1000, batch_size=100):\n",
        "    \"\"\"\n",
        "    Send events to Snowflake via REST API\n",
        "    \n",
        "    This function demonstrates the complete Snowpipe Streaming workflow:\n",
        "    1. Get control host\n",
        "    2. Open channel  \n",
        "    3. POST data in batches\n",
        "    \"\"\"\n",
        "    \n",
        "    channel_name = f\"rfid_demo_{int(time.time())}\"\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\"STREAMING DEMO STARTING\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    \n",
        "    # STEP 1: Get control plane host\n",
        "    print(\"Step 1: Discovering control plane...\")\n",
        "    control_host = client.get_control_host()\n",
        "    print(f\"   Control host: {control_host}\")\n",
        "    print()\n",
        "    \n",
        "    # STEP 2: Open streaming channel\n",
        "    print(f\"Step 2: Opening channel '{channel_name}'...\")\n",
        "    channel_data = client.open_channel(channel_name)\n",
        "    print(f\"   Channel opened!\")\n",
        "    print(f\"   Ingest host: {client.ingest_host}\")\n",
        "    print(f\"   Token: {client.scoped_token[:20]}...\")\n",
        "    print()\n",
        "    \n",
        "    # STEP 3: Stream data in batches\n",
        "    print(f\"Step 3: Streaming {num_events} events via HTTP POST...\")\n",
        "    print()\n",
        "    \n",
        "    total_sent = 0\n",
        "    start_time = time.time()\n",
        "    num_batches = (num_events + batch_size - 1) // batch_size\n",
        "    \n",
        "    for batch_num in range(num_batches):\n",
        "        # Generate batch\n",
        "        batch_count = min(batch_size, num_events - total_sent)\n",
        "        events = generator.generate_batch(batch_count)\n",
        "        \n",
        "        # Send via REST API - THIS IS THE STAR OF THE SHOW!\n",
        "        result = client.insert_rows(channel_name, events)\n",
        "        \n",
        "        total_sent += batch_count\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = total_sent / elapsed if elapsed > 0 else 0\n",
        "        \n",
        "        # Progress indicator\n",
        "        progress = \"‚ñà\" * (batch_num + 1) + \"‚ñë\" * (num_batches - batch_num - 1)\n",
        "        print(f\"   [{progress}] Batch {batch_num + 1}/{num_batches}: \"\n",
        "              f\"{total_sent:,} events | {rate:.0f} events/sec\")\n",
        "        \n",
        "        # Brief pause between batches\n",
        "        time.sleep(0.1)\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print()\n",
        "    print(\"=\"*70)\n",
        "    print(\"STREAMING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"   Events sent: {total_sent:,}\")\n",
        "    print(f\"   Duration: {elapsed:.2f} seconds\")\n",
        "    print(f\"   Throughput: {total_sent/elapsed:.0f} events/sec\")\n",
        "    print(f\"   Channel: {channel_name}\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    print(\"Data is now flowing through Snowflake's pipeline:\")\n",
        "    print(\"   REST API -> Pipe -> RAW table -> Stream -> Task -> STAGING -> ANALYTICS\")\n",
        "    print()\n",
        "    \n",
        "    return total_sent\n",
        "\n",
        "# RUN THE DEMO!\n",
        "events_sent = stream_events_to_snowflake(num_events=1000, batch_size=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Verify Data Landed in Snowflake\n",
        "\n",
        "Let's query your tables to confirm the data arrived and flowed through the pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data landed and check pipeline status\n",
        "print(\"Checking your tables...\")\n",
        "print()\n",
        "print(\"Waiting 5 seconds for ingestion to complete...\")\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PIPELINE STATUS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Query actual row counts from YOUR tables\n",
        "raw_count = session.sql(\n",
        "    \"SELECT COUNT(*) as cnt FROM SNOWFLAKE_EXAMPLE.RAW_INGESTION.RAW_BADGE_EVENTS\"\n",
        ").collect()[0]['CNT']\n",
        "\n",
        "staging_count = session.sql(\n",
        "    \"SELECT COUNT(*) as cnt FROM SNOWFLAKE_EXAMPLE.STAGING_LAYER.STG_BADGE_EVENTS\"\n",
        ").collect()[0]['CNT']\n",
        "\n",
        "analytics_count = session.sql(\n",
        "    \"SELECT COUNT(*) as cnt FROM SNOWFLAKE_EXAMPLE.ANALYTICS_LAYER.FCT_ACCESS_EVENTS\"\n",
        ").collect()[0]['CNT']\n",
        "\n",
        "# Check if stream still has data (means tasks are processing)\n",
        "stream_status = session.sql(\n",
        "    \"SELECT SYSTEM$STREAM_HAS_DATA('SNOWFLAKE_EXAMPLE.RAW_INGESTION.sfe_badge_events_stream') as has_data\"\n",
        ").collect()[0]['HAS_DATA']\n",
        "\n",
        "# Display results\n",
        "print()\n",
        "print(f\"{'Layer':<20} {'Row Count':>15} {'Status'}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'RAW_BADGE_EVENTS':<20} {raw_count:>15,} {'PASS - Received' if raw_count > 0 else 'FAIL - No data'}\")\n",
        "print(f\"{'STG_BADGE_EVENTS':<20} {staging_count:>15,} {'PASS - Processed' if staging_count > 0 else 'Processing...'}\")\n",
        "print(f\"{'FCT_ACCESS_EVENTS':<20} {analytics_count:>15,} {'PASS - Transformed' if analytics_count > 0 else 'Processing...'}\")\n",
        "print()\n",
        "print(f\"Stream Status: {'Processing' if stream_status else 'Empty (all caught up)'}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Success message\n",
        "if raw_count >= events_sent:\n",
        "    print()\n",
        "    print(\"SUCCESS! Your data is in Snowflake!\")\n",
        "    print(f\"   You sent {events_sent:,} events via REST API\")\n",
        "    print(f\"   Snowflake received {raw_count:,} events\")\n",
        "    print()\n",
        "    \n",
        "    if staging_count == raw_count and analytics_count == raw_count:\n",
        "        print(\"BONUS: Complete end-to-end pipeline validated!\")\n",
        "        print(\"   Data flowed: REST API -> RAW -> Stream -> Task -> STAGING -> ANALYTICS\")\n",
        "    elif staging_count > 0 or analytics_count > 0:\n",
        "        print(\"Pipeline still processing downstream tables (normal)\")\n",
        "        print(\"   Wait 1-2 minutes for tasks to complete, then re-run this cell\")\n",
        "else:\n",
        "    print()\n",
        "    print(\"Data still arriving (wait a few seconds and re-run)\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: View Your Data\n",
        "\n",
        "Let's look at the actual events that just arrived in your tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample events from RAW table\n",
        "print(\"=\"*70)\n",
        "print(\"SAMPLE EVENTS FROM YOUR RAW TABLE (Most Recent)\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "sample_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        badge_id,\n",
        "        user_id,\n",
        "        zone_id,\n",
        "        event_type,\n",
        "        event_timestamp,\n",
        "        ingestion_time\n",
        "    FROM SNOWFLAKE_EXAMPLE.RAW_INGESTION.RAW_BADGE_EVENTS\n",
        "    ORDER BY ingestion_time DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "\n",
        "sample_df.show()\n",
        "\n",
        "# Show analytics summary\n",
        "print()\n",
        "print(\"=\"*70)\n",
        "print(\"ANALYTICS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "summary_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        event_type,\n",
        "        COUNT(*) as event_count,\n",
        "        COUNT(DISTINCT user_id) as unique_users,\n",
        "        COUNT(DISTINCT zone_id) as unique_zones\n",
        "    FROM SNOWFLAKE_EXAMPLE.RAW_INGESTION.RAW_BADGE_EVENTS\n",
        "    GROUP BY event_type\n",
        "    ORDER BY event_count DESC\n",
        "\"\"\")\n",
        "\n",
        "summary_df.show()\n",
        "\n",
        "print()\n",
        "print(\"=\"*70)\n",
        "print(\"DEMO COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "print(\"What you just saw:\")\n",
        "print(\"  - REST API authentication (JWT)\")\n",
        "print(\"  - Streaming channel opened\")\n",
        "print(\"  - 1,000 events sent via HTTP POST\")\n",
        "print(\"  - Data landed in Snowflake in seconds\")\n",
        "print(\"  - No middleware required\")\n",
        "print()\n",
        "print(\"Next steps:\")\n",
        "print(\"  - Explore the ANALYTICS_LAYER tables for transformed data\")\n",
        "print(\"  - Check sql/03_monitoring/monitoring_views.sql for pipeline metrics\")\n",
        "print(\"  - Try modifying num_events and batch_size in the demo function\")\n",
        "print(\"  - Review the REST API calls in the SnowpipeStreamingClient class\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Snowpipe Streaming REST API Client\n",
        "# Demonstrates the complete REST API workflow\n",
        "\n",
        "class SnowpipeStreamingClient:\n",
        "    \"\"\"Client for Snowflake Snowpipe Streaming REST API\"\"\"\n",
        "    \n",
        "    def __init__(self, auth, database, schema, pipe):\n",
        "        self.auth = auth\n",
        "        self.database = database\n",
        "        self.schema = schema\n",
        "        self.pipe = pipe\n",
        "        \n",
        "        # Build account URL\n",
        "        account_for_url = auth.account.replace('_', '-').lower()\n",
        "        self.account_url = f\"https://{account_for_url}.snowflakecomputing.com\"\n",
        "        \n",
        "        # Session state\n",
        "        self.control_host = None\n",
        "        self.ingest_host = None\n",
        "        self.scoped_token = None\n",
        "        self.continuation_token = None\n",
        "    \n",
        "    def get_control_host(self):\n",
        "        \"\"\"Step 1: Get control plane hostname\"\"\"\n",
        "        jwt_token = self.auth.generate_jwt()\n",
        "        \n",
        "        response = requests.get(\n",
        "            f\"{self.account_url}/v2/streaming/hostname\",\n",
        "            headers={\"Authorization\": f\"Bearer {jwt_token}\"}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        self.control_host = response.text.strip('\"')\n",
        "        print(f\"   Control host: {self.control_host}\")\n",
        "        return self.control_host\n",
        "    \n",
        "    def open_channel(self, channel_name):\n",
        "        \"\"\"Step 2: Open streaming channel\"\"\"\n",
        "        if not self.control_host:\n",
        "            self.get_control_host()\n",
        "        \n",
        "        jwt_token = self.auth.generate_jwt()\n",
        "        url = f\"https://{self.control_host}/v2/streaming/databases/{self.database}/schemas/{self.schema}/pipes/{self.pipe}:open-channel\"\n",
        "        \n",
        "        response = requests.post(\n",
        "            url,\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {jwt_token}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            },\n",
        "            json={\"channel_name\": channel_name}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        data = response.json()\n",
        "        self.ingest_host = data['ingest_host']\n",
        "        self.scoped_token = data['scoped_token']\n",
        "        self.continuation_token = data['continuation_token']\n",
        "        \n",
        "        print(f\"   ‚úÖ Channel '{channel_name}' opened\")\n",
        "        print(f\"   Ingest host: {self.ingest_host}\")\n",
        "        return data\n",
        "    \n",
        "    def insert_rows(self, channel_name, rows):\n",
        "        \"\"\"Step 3: Insert rows via REST API - THIS IS THE KEY DEMO!\"\"\"\n",
        "        url = f\"https://{self.ingest_host}/v2/streaming/databases/{self.database}/schemas/{self.schema}/pipes/{self.pipe}/channels/{channel_name}:insert-rows\"\n",
        "        \n",
        "        response = requests.post(\n",
        "            url,\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {self.scoped_token}\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"X-Snowflake-Streaming-Continuation-Token\": self.continuation_token\n",
        "            },\n",
        "            json={\"rows\": rows}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        result = response.json()\n",
        "        self.continuation_token = result.get('continuation_token', self.continuation_token)\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Initialize client\n",
        "client = SnowpipeStreamingClient(\n",
        "    auth=auth,\n",
        "    database=config['database'],\n",
        "    schema=config['schema'],\n",
        "    pipe=config['pipe']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Snowpipe Streaming client initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: RFID Badge Event Generator\n",
        "# Generates realistic badge scan events\n",
        "\n",
        "class BadgeEventGenerator:\n",
        "    \"\"\"Generate realistic RFID badge events\"\"\"\n",
        "    \n",
        "    def __init__(self, num_users=100, num_zones=20, num_readers=10):\n",
        "        self.badge_ids = [f\"BADGE-{str(i).zfill(5)}\" for i in range(1, num_users + 1)]\n",
        "        self.user_ids = [f\"USR-{str(i).zfill(3)}\" for i in range(1, num_users + 1)]\n",
        "        self.zone_ids = [f\"ZONE-{zone_type}-{i}\" \n",
        "                        for zone_type in [\"LOBBY\", \"OFFICE\", \"CONF\", \"SECURE\", \"PARKING\"]\n",
        "                        for i in range(1, (num_zones // 5) + 1)]\n",
        "        self.reader_ids = [f\"RDR-{str(i).zfill(3)}\" for i in range(1, num_readers + 1)]\n",
        "        self.directions = [\"ENTRY\", \"EXIT\"]\n",
        "    \n",
        "    def generate_event(self, timestamp=None):\n",
        "        \"\"\"Generate a single badge event\"\"\"\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.utcnow()\n",
        "        \n",
        "        user_idx = random.randint(0, len(self.user_ids) - 1)\n",
        "        \n",
        "        event = {\n",
        "            \"badge_id\": self.badge_ids[user_idx],\n",
        "            \"user_id\": self.user_ids[user_idx],\n",
        "            \"zone_id\": random.choice(self.zone_ids),\n",
        "            \"event_timestamp\": timestamp.isoformat() + \"Z\",\n",
        "            \"event_type\": random.choice(self.directions),\n",
        "            \"reader_id\": random.choice(self.reader_ids),\n",
        "            \"signal_strength\": random.randint(-85, -20),  # dBm\n",
        "            \"direction\": random.choice(self.directions)\n",
        "        }\n",
        "        \n",
        "        return event\n",
        "    \n",
        "    def generate_batch(self, count=100, start_time=None):\n",
        "        \"\"\"Generate a batch of events\"\"\"\n",
        "        if start_time is None:\n",
        "            start_time = datetime.utcnow()\n",
        "        \n",
        "        events = []\n",
        "        for i in range(count):\n",
        "            # Spread events over time (0.01 seconds apart)\n",
        "            timestamp = start_time + timedelta(seconds=i*0.01)\n",
        "            events.append(self.generate_event(timestamp))\n",
        "        \n",
        "        return events\n",
        "\n",
        "# Initialize generator\n",
        "generator = BadgeEventGenerator(num_users=100, num_zones=20, num_readers=10)\n",
        "\n",
        "# Test generation\n",
        "sample_event = generator.generate_event()\n",
        "print(\"‚úÖ Event generator initialized\")\n",
        "print(f\"   Sample event: {json.dumps(sample_event, indent=2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Run the Simulation\n",
        "\n",
        "This is where the magic happens! We'll:\n",
        "1. Open a streaming channel\n",
        "2. Generate badge events\n",
        "3. Send them via REST API POST\n",
        "4. Validate they arrived in Snowflake\n",
        "\n",
        "**This demonstrates the core value:** Direct HTTP ingestion with no middleware!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Execute Simulation - Send Data via REST API\n",
        "# This is the main demo of Snowpipe Streaming REST API!\n",
        "\n",
        "def run_simulation(num_events=1000, batch_size=100):\n",
        "    \"\"\"Run RFID simulation - sends data to Snowflake REST API\"\"\"\n",
        "    \n",
        "    channel_name = f\"rfid_channel_{int(time.time())}\"\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\"üöÄ Starting RFID Badge Event Simulation\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    \n",
        "    # Step 1: Get control host\n",
        "    print(\"üì° Step 1: Getting control plane hostname...\")\n",
        "    client.get_control_host()\n",
        "    print()\n",
        "    \n",
        "    # Step 2: Open channel\n",
        "    print(f\"üîì Step 2: Opening streaming channel '{channel_name}'...\")\n",
        "    client.open_channel(channel_name)\n",
        "    print()\n",
        "    \n",
        "    # Step 3: Send events in batches\n",
        "    print(f\"üì§ Step 3: Sending {num_events} events via REST API...\")\n",
        "    total_sent = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    num_batches = (num_events + batch_size - 1) // batch_size\n",
        "    \n",
        "    for batch_num in range(num_batches):\n",
        "        # Generate batch\n",
        "        batch_count = min(batch_size, num_events - total_sent)\n",
        "        events = generator.generate_batch(batch_count)\n",
        "        \n",
        "        # Send via REST API - THIS IS THE KEY DEMO!\n",
        "        result = client.insert_rows(channel_name, events)\n",
        "        \n",
        "        total_sent += batch_count\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = total_sent / elapsed if elapsed > 0 else 0\n",
        "        \n",
        "        print(f\"   Batch {batch_num + 1}/{num_batches}: {batch_count} events sent | \"\n",
        "              f\"Total: {total_sent} | Rate: {rate:.0f} events/sec\")\n",
        "        \n",
        "        # Brief pause between batches\n",
        "        time.sleep(0.1)\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    print()\n",
        "    print(\"=\"*70)\n",
        "    print(f\"‚úÖ Simulation Complete!\")\n",
        "    print(f\"   Events sent: {total_sent}\")\n",
        "    print(f\"   Duration: {elapsed:.2f} seconds\")\n",
        "    print(f\"   Average rate: {total_sent/elapsed:.0f} events/sec\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    \n",
        "    return total_sent\n",
        "\n",
        "# Run simulation with 1000 events\n",
        "events_sent = run_simulation(num_events=1000, batch_size=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Validate Data Arrived in Snowflake\n",
        "# Query the table to confirm REST API ingestion worked\n",
        "\n",
        "def validate_pipeline():\n",
        "    \"\"\"Check that events made it through the pipeline\"\"\"\n",
        "    session = get_session()\n",
        "    \n",
        "    print(\"üîç Validating data pipeline...\")\n",
        "    print()\n",
        "    \n",
        "    # Wait a moment for ingestion to complete\n",
        "    print(\"   Waiting 5 seconds for ingestion to complete...\")\n",
        "    time.sleep(5)\n",
        "    \n",
        "    # Check raw table\n",
        "    raw_count = session.sql(\n",
        "        \"SELECT COUNT(*) FROM SNOWFLAKE_EXAMPLE.STAGE_BADGE_TRACKING.RAW_BADGE_EVENTS\"\n",
        "    ).collect()[0][0]\n",
        "    \n",
        "    # Check staging table\n",
        "    staging_count = session.sql(\n",
        "        \"SELECT COUNT(*) FROM SNOWFLAKE_EXAMPLE.TRANSFORM_BADGE_TRACKING.STG_BADGE_EVENTS\"\n",
        "    ).collect()[0][0]\n",
        "    \n",
        "    # Check analytics table\n",
        "    analytics_count = session.sql(\n",
        "        \"SELECT COUNT(*) FROM SNOWFLAKE_EXAMPLE.ANALYTICS_BADGE_TRACKING.FCT_ACCESS_EVENTS\"\n",
        "    ).collect()[0][0]\n",
        "    \n",
        "    # Check stream status\n",
        "    stream_has_data = session.sql(\n",
        "        \"SELECT SYSTEM$STREAM_HAS_DATA('SNOWFLAKE_EXAMPLE.STAGE_BADGE_TRACKING.raw_badge_events_stream')\"\n",
        "    ).collect()[0][0]\n",
        "    \n",
        "    print(\"üìä Pipeline Status:\")\n",
        "    print(\"   \" + \"=\"*66)\n",
        "    print(f\"   {'Layer':<20} | {'Row Count':>10} | {'Status':>30}\")\n",
        "    print(\"   \" + \"-\"*66)\n",
        "    print(f\"   {'RAW':<20} | {raw_count:>10,} | {'‚úÖ Data received' if raw_count > 0 else '‚ùå No data'}\")\n",
        "    print(f\"   {'STAGING':<20} | {staging_count:>10,} | {'‚úÖ Processed' if staging_count > 0 else '‚è≥ Processing'}\")\n",
        "    print(f\"   {'ANALYTICS':<20} | {analytics_count:>10,} | {'‚úÖ Transformed' if analytics_count > 0 else '‚è≥ Processing'}\")\n",
        "    print(\"   \" + \"=\"*66)\n",
        "    print(f\"   Stream Status: {'‚è≥ Processing' if stream_has_data else '‚úÖ Empty (all processed)'}\")\n",
        "    print()\n",
        "    \n",
        "    if raw_count > 0:\n",
        "        print(\"   ‚úÖ SUCCESS! REST API ingestion is working!\")\n",
        "        print(\"   Data flowed: REST API ‚Üí Snowpipe ‚Üí RAW table\")\n",
        "        \n",
        "        if staging_count == raw_count and analytics_count == raw_count:\n",
        "            print(\"   ‚úÖ BONUS! Complete pipeline validated!\")\n",
        "            print(\"   Data flowed: RAW ‚Üí Streams ‚Üí Tasks ‚Üí STAGING ‚Üí ANALYTICS\")\n",
        "        elif staging_count > 0 or analytics_count > 0:\n",
        "            print(\"   ‚è≥ Pipeline still processing... (wait 1-2 minutes for tasks)\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  No data in RAW table yet. Wait a few seconds and re-run.\")\n",
        "    \n",
        "    print()\n",
        "    \n",
        "    # Show sample events\n",
        "    if raw_count > 0:\n",
        "        print(\"üìã Sample Events (first 5):\")\n",
        "        sample_df = session.sql(\n",
        "            \"SELECT badge_id, zone_id, event_timestamp, event_type \"\n",
        "            \"FROM SNOWFLAKE_EXAMPLE.STAGE_BADGE_TRACKING.RAW_BADGE_EVENTS \"\n",
        "            \"ORDER BY ingestion_time DESC LIMIT 5\"\n",
        "        )\n",
        "        sample_df.show()\n",
        "\n",
        "# Run validation\n",
        "validate_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ What We Just Demonstrated\n",
        "\n",
        "This notebook showcased **Snowflake's Snowpipe Streaming REST API**:\n",
        "\n",
        "### Key Capabilities:\n",
        "1. **Native HTTP Ingestion** - No external infrastructure required\n",
        "2. **JWT Authentication** - Secure key-pair auth with RS256\n",
        "3. **Channel-Based Streaming** - Isolated streams with continuation tokens\n",
        "4. **High Performance** - 1000+ events/sec with sub-second batching\n",
        "5. **Low Latency** - <10 seconds from POST to queryable data\n",
        "\n",
        "### The API Workflow:\n",
        "```\n",
        "1. GET /v2/streaming/hostname\n",
        "   ‚Üí Returns control plane host\n",
        "\n",
        "2. POST /v2/streaming/.../pipes/{PIPE}:open-channel\n",
        "   ‚Üí Opens channel, returns ingest host + scoped token\n",
        "\n",
        "3. POST /v2/streaming/.../channels/{CHANNEL}:insert-rows\n",
        "   ‚Üí Sends data via HTTP POST (THIS IS THE STAR!)\n",
        "   ‚Üí Includes continuation token for ordering\n",
        "\n",
        "4. Data flows automatically:\n",
        "   REST API ‚Üí PIPE ‚Üí RAW table ‚Üí Stream ‚Üí Task ‚Üí STAGING ‚Üí ANALYTICS\n",
        "```\n",
        "\n",
        "### Why This Matters:\n",
        "- **Zero middleware** - RFID vendors POST directly to Snowflake\n",
        "- **Snowflake-native** - No Kafka, no message queues, no external services\n",
        "- **Production-ready** - GA since September 2024, supports 10 GB/sec per table\n",
        "- **Cost-efficient** - Throughput-based pricing, no compute overhead\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Next Steps\n",
        "\n",
        "1. **View the data:**\n",
        "   ```sql\n",
        "   SELECT * FROM SNOWFLAKE_EXAMPLE.ANALYTICS_BADGE_TRACKING.FCT_ACCESS_EVENTS\n",
        "   ORDER BY event_timestamp DESC LIMIT 100;\n",
        "   ```\n",
        "\n",
        "2. **Test with curl:**\n",
        "   See `README.md#tldr` for direct curl commands to hit the REST API\n",
        "\n",
        "3. **Explore the pipeline:**\n",
        "   - Streams: `SHOW STREAMS IN DATABASE SNOWFLAKE_EXAMPLE;`\n",
        "   - Tasks: `SHOW TASKS IN DATABASE SNOWFLAKE_EXAMPLE;`\n",
        "   - Monitoring: Query `sql/03_monitoring/monitoring_views.sql`\n",
        "\n",
        "4. **Customize:**\n",
        "   - Modify event schema: `sql/01_setup/01_core_setup.sql` (RAW_BADGE_EVENTS table)\n",
        "   - Add transformations: `sql/01_setup/01_core_setup.sql` (PIPE definition)\n",
        "   - Extend analytics model: `sql/01_setup/02_analytics_layer.sql` (dimensions/facts)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "snowpark_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
